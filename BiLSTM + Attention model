{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13802091,"sourceType":"datasetVersion","datasetId":8787854}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:33:52.184166Z","iopub.execute_input":"2025-11-24T18:33:52.184354Z","iopub.status.idle":"2025-11-24T18:33:54.446241Z","shell.execute_reply.started":"2025-11-24T18:33:52.184336Z","shell.execute_reply":"2025-11-24T18:33:54.445417Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/lastly/collect_preprocessed_dataset.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install scikit-learn pandas numpy torch matplotlib seaborn\n\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    hamming_loss, jaccard_score, multilabel_confusion_matrix\n)\nfrom torch.nn.utils.rnn import pad_sequence\nimport re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:36:07.516626Z","iopub.execute_input":"2025-11-24T18:36:07.517678Z","iopub.status.idle":"2025-11-24T18:37:34.434417Z","shell.execute_reply.started":"2025-11-24T18:36:07.517648Z","shell.execute_reply":"2025-11-24T18:37:34.433837Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.20.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.10.0)\nCollecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.3.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.6.82\n    Uninstalling nvidia-curand-cu12-10.3.6.82:\n      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n  Attempting uninstall: nvidia-cuda-runtime-cu12\n    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n  Attempting uninstall: nvidia-cuda-cupti-cu12\n    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def normalize(text):\n    text = text.lower()\n    text = re.sub(r\"[^a-zA-Z0-9?! ]\", \" \", text)\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:38:17.742311Z","iopub.execute_input":"2025-11-24T18:38:17.743144Z","iopub.status.idle":"2025-11-24T18:38:17.746940Z","shell.execute_reply.started":"2025-11-24T18:38:17.743115Z","shell.execute_reply":"2025-11-24T18:38:17.746373Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/lastly/collect_preprocessed_dataset.csv\")\n\nlabel_cols = ['Love','Joy','Anger','Surprise','Sadness','Fear','Hate']\ndf[label_cols] = df[label_cols].astype(int)\n\ntexts = df[\"Data\"].astype(str).apply(normalize).tolist()\nlabels = df[label_cols].values\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:38:57.496565Z","iopub.execute_input":"2025-11-24T18:38:57.497312Z","iopub.status.idle":"2025-11-24T18:38:57.832542Z","shell.execute_reply.started":"2025-11-24T18:38:57.497282Z","shell.execute_reply":"2025-11-24T18:38:57.831975Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from collections import Counter\n\ndef build_vocab(texts, min_freq=2):\n    counter = Counter()\n    for text in texts:\n        counter.update(text.split())\n    vocab = {\"<PAD>\":0, \"<UNK>\":1}\n    for w,f in counter.items():\n        if f >= min_freq:\n            vocab[w] = len(vocab)\n    return vocab\n\nvocab = build_vocab(texts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:39:09.992821Z","iopub.execute_input":"2025-11-24T18:39:09.993528Z","iopub.status.idle":"2025-11-24T18:39:10.069649Z","shell.execute_reply.started":"2025-11-24T18:39:09.993492Z","shell.execute_reply":"2025-11-24T18:39:10.068939Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def encode(text):\n    return torch.tensor([vocab.get(w, 1) for w in text.split()], dtype=torch.long)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:39:19.850605Z","iopub.execute_input":"2025-11-24T18:39:19.850880Z","iopub.status.idle":"2025-11-24T18:39:19.854834Z","shell.execute_reply.started":"2025-11-24T18:39:19.850859Z","shell.execute_reply":"2025-11-24T18:39:19.854088Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class EmotionDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = [encode(t) for t in texts]\n        self.labels = torch.tensor(labels, dtype=torch.float32)\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        return self.texts[idx], self.labels[idx]\n\n\ndef collate_fn(batch):\n    seq, lbl = zip(*batch)\n    padded = pad_sequence(seq, batch_first=True, padding_value=0)\n    return padded, torch.stack(lbl)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:39:28.832950Z","iopub.execute_input":"2025-11-24T18:39:28.833223Z","iopub.status.idle":"2025-11-24T18:39:28.839289Z","shell.execute_reply.started":"2025-11-24T18:39:28.833202Z","shell.execute_reply":"2025-11-24T18:39:28.838546Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(\n    texts, labels, test_size=0.2, random_state=42\n)\n\ntrain_ds = EmotionDataset(X_train, y_train)\nval_ds   = EmotionDataset(X_val, y_val)\n\ntrain_loader = DataLoader(train_ds, batch_size=32, shuffle=True, collate_fn=collate_fn)\nval_loader   = DataLoader(val_ds, batch_size=32, shuffle=False, collate_fn=collate_fn)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:39:38.775224Z","iopub.execute_input":"2025-11-24T18:39:38.775487Z","iopub.status.idle":"2025-11-24T18:39:39.195316Z","shell.execute_reply.started":"2025-11-24T18:39:38.775467Z","shell.execute_reply":"2025-11-24T18:39:39.194506Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class Attention(nn.Module):\n    def __init__(self, hidden_dim):\n        super().__init__()\n        self.attention = nn.Linear(hidden_dim, 1)\n\n    def forward(self, lstm_output):\n        scores = self.attention(lstm_output).squeeze(-1)\n        weights = torch.softmax(scores, dim=1)\n        context = torch.sum(lstm_output * weights.unsqueeze(-1), dim=1)\n        return context\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:39:50.936171Z","iopub.execute_input":"2025-11-24T18:39:50.936694Z","iopub.status.idle":"2025-11-24T18:39:50.941803Z","shell.execute_reply.started":"2025-11-24T18:39:50.936665Z","shell.execute_reply":"2025-11-24T18:39:50.940978Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"class BiLSTM_Attention(nn.Module):\n    def __init__(self, vocab_size, embed_dim, hidden_dim, num_labels):\n        super().__init__()\n\n        self.embedding = nn.Embedding(vocab_size, embed_dim)\n        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True, bidirectional=True)\n        self.attention = Attention(hidden_dim*2)\n        self.fc = nn.Linear(hidden_dim*2, num_labels)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.embedding(x)\n        lstm_out, _ = self.lstm(x)\n        context = self.attention(lstm_out)\n        out = self.fc(context)\n        return self.sigmoid(out)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:40:02.852427Z","iopub.execute_input":"2025-11-24T18:40:02.852726Z","iopub.status.idle":"2025-11-24T18:40:02.857903Z","shell.execute_reply.started":"2025-11-24T18:40:02.852703Z","shell.execute_reply":"2025-11-24T18:40:02.857317Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nmodel = BiLSTM_Attention(\n    vocab_size=len(vocab),\n    embed_dim=128,\n    hidden_dim=256,\n    num_labels=len(label_cols)\n).to(device)\n\ncriterion = nn.BCELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:40:19.239748Z","iopub.execute_input":"2025-11-24T18:40:19.240029Z","iopub.status.idle":"2025-11-24T18:40:23.010804Z","shell.execute_reply.started":"2025-11-24T18:40:19.240007Z","shell.execute_reply":"2025-11-24T18:40:23.009985Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def evaluate_metrics(y_true, y_pred):\n    y_pred_bin = (y_pred > 0.5).astype(int)\n\n    return {\n        \"accuracy_exact\": accuracy_score(y_true, y_pred_bin),\n        \"precision_macro\": precision_score(y_true, y_pred_bin, average=\"macro\", zero_division=0),\n        \"recall_macro\": recall_score(y_true, y_pred_bin, average=\"macro\", zero_division=0),\n        \"f1_macro\": f1_score(y_true, y_pred_bin, average=\"macro\", zero_division=0),\n        \"hamming\": hamming_loss(y_true, y_pred_bin),\n        \"jaccard_samples\": jaccard_score(y_true, y_pred_bin, average=\"samples\", zero_division=0),\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:40:36.112476Z","iopub.execute_input":"2025-11-24T18:40:36.113462Z","iopub.status.idle":"2025-11-24T18:40:36.117951Z","shell.execute_reply.started":"2025-11-24T18:40:36.113434Z","shell.execute_reply":"2025-11-24T18:40:36.117228Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def train_epoch():\n    model.train()\n    total_loss = 0\n    for x, y in train_loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n        preds = model(x)\n        loss = criterion(preds, y)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n    return total_loss / len(train_loader)\n\n\ndef evaluate():\n    model.eval()\n    all_preds, all_labels = [], []\n    \n    with torch.no_grad():\n        for x, y in val_loader:\n            x = x.to(device)\n            preds = model(x).cpu().numpy()\n            all_preds.append(preds)\n            all_labels.append(y.numpy())\n\n    preds = np.vstack(all_preds)\n    labels = np.vstack(all_labels)\n\n    return evaluate_metrics(labels, preds), preds, labels\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:40:46.762638Z","iopub.execute_input":"2025-11-24T18:40:46.762914Z","iopub.status.idle":"2025-11-24T18:40:46.768562Z","shell.execute_reply.started":"2025-11-24T18:40:46.762893Z","shell.execute_reply":"2025-11-24T18:40:46.767845Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"for epoch in range(15):\n    loss = train_epoch()\n    metrics, preds, labels = evaluate()\n\n    print(f\"\\nEpoch {epoch+1}\")\n    print(\"Training Loss:\", loss)\n    for k,v in metrics.items():\n        print(f\"{k}: {v:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:40:58.971083Z","iopub.execute_input":"2025-11-24T18:40:58.971812Z","iopub.status.idle":"2025-11-24T18:42:15.897217Z","shell.execute_reply.started":"2025-11-24T18:40:58.971784Z","shell.execute_reply":"2025-11-24T18:42:15.896496Z"}},"outputs":[{"name":"stdout","text":"\nEpoch 1\nTraining Loss: 0.37154886445522994\naccuracy_exact: 0.2589\nprecision_macro: 0.7604\nrecall_macro: 0.2712\nf1_macro: 0.3766\nhamming: 0.1259\njaccard_samples: 0.2660\n\nEpoch 2\nTraining Loss: 0.27552576037659043\naccuracy_exact: 0.3918\nprecision_macro: 0.7090\nrecall_macro: 0.4321\nf1_macro: 0.5327\nhamming: 0.1139\njaccard_samples: 0.4160\n\nEpoch 3\nTraining Loss: 0.2134614091623446\naccuracy_exact: 0.4558\nprecision_macro: 0.6848\nrecall_macro: 0.5208\nf1_macro: 0.5904\nhamming: 0.1102\njaccard_samples: 0.4941\n\nEpoch 4\nTraining Loss: 0.15580048045978465\naccuracy_exact: 0.4926\nprecision_macro: 0.6788\nrecall_macro: 0.5693\nf1_macro: 0.6182\nhamming: 0.1074\njaccard_samples: 0.5339\n\nEpoch 5\nTraining Loss: 0.10416991609394893\naccuracy_exact: 0.5115\nprecision_macro: 0.6770\nrecall_macro: 0.5847\nf1_macro: 0.6249\nhamming: 0.1067\njaccard_samples: 0.5533\n\nEpoch 6\nTraining Loss: 0.06377363013606732\naccuracy_exact: 0.5165\nprecision_macro: 0.6657\nrecall_macro: 0.5923\nf1_macro: 0.6258\nhamming: 0.1081\njaccard_samples: 0.5578\n\nEpoch 7\nTraining Loss: 0.03765432169826851\naccuracy_exact: 0.5083\nprecision_macro: 0.6655\nrecall_macro: 0.5871\nf1_macro: 0.6234\nhamming: 0.1089\njaccard_samples: 0.5517\n\nEpoch 8\nTraining Loss: 0.023897883802085\naccuracy_exact: 0.5261\nprecision_macro: 0.6630\nrecall_macro: 0.6070\nf1_macro: 0.6325\nhamming: 0.1082\njaccard_samples: 0.5706\n\nEpoch 9\nTraining Loss: 0.014738501189744914\naccuracy_exact: 0.5178\nprecision_macro: 0.6567\nrecall_macro: 0.6057\nf1_macro: 0.6298\nhamming: 0.1092\njaccard_samples: 0.5640\n\nEpoch 10\nTraining Loss: 0.011658744564535492\naccuracy_exact: 0.5246\nprecision_macro: 0.6586\nrecall_macro: 0.6210\nf1_macro: 0.6387\nhamming: 0.1091\njaccard_samples: 0.5751\n\nEpoch 11\nTraining Loss: 0.010160499407933897\naccuracy_exact: 0.5167\nprecision_macro: 0.6676\nrecall_macro: 0.5996\nf1_macro: 0.6309\nhamming: 0.1078\njaccard_samples: 0.5607\n\nEpoch 12\nTraining Loss: 0.008003070737665449\naccuracy_exact: 0.5200\nprecision_macro: 0.6564\nrecall_macro: 0.6016\nf1_macro: 0.6272\nhamming: 0.1089\njaccard_samples: 0.5633\n\nEpoch 13\nTraining Loss: 0.007552924461682172\naccuracy_exact: 0.5137\nprecision_macro: 0.6496\nrecall_macro: 0.6048\nf1_macro: 0.6261\nhamming: 0.1110\njaccard_samples: 0.5613\n\nEpoch 14\nTraining Loss: 0.010004260321432088\naccuracy_exact: 0.5092\nprecision_macro: 0.6588\nrecall_macro: 0.5981\nf1_macro: 0.6262\nhamming: 0.1092\njaccard_samples: 0.5574\n\nEpoch 15\nTraining Loss: 0.006750198595972475\naccuracy_exact: 0.5219\nprecision_macro: 0.6576\nrecall_macro: 0.6116\nf1_macro: 0.6335\nhamming: 0.1087\njaccard_samples: 0.5682\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/bilstm_attention.pt\")\nprint(\"Model Saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:42:25.975044Z","iopub.execute_input":"2025-11-24T18:42:25.975799Z","iopub.status.idle":"2025-11-24T18:42:26.003794Z","shell.execute_reply.started":"2025-11-24T18:42:25.975772Z","shell.execute_reply":"2025-11-24T18:42:26.003160Z"}},"outputs":[{"name":"stdout","text":"Model Saved!\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def predict(text):\n    model.eval()\n    text = normalize(text)\n    tokens = encode(text).unsqueeze(0).to(device)\n\n    with torch.no_grad():\n        probs = model(tokens).cpu().numpy()[0]\n\n    return dict(zip(label_cols, probs))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:42:38.610769Z","iopub.execute_input":"2025-11-24T18:42:38.611388Z","iopub.status.idle":"2025-11-24T18:42:38.615682Z","shell.execute_reply.started":"2025-11-24T18:42:38.611363Z","shell.execute_reply":"2025-11-24T18:42:38.615098Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(predict(\"Ami ajke khub happy feel korchi\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:42:49.915272Z","iopub.execute_input":"2025-11-24T18:42:49.915921Z","iopub.status.idle":"2025-11-24T18:42:49.922496Z","shell.execute_reply.started":"2025-11-24T18:42:49.915894Z","shell.execute_reply":"2025-11-24T18:42:49.921862Z"}},"outputs":[{"name":"stdout","text":"{'Love': 0.19296378, 'Joy': 9.275691e-09, 'Anger': 3.60514e-05, 'Surprise': 9.7692464e-08, 'Sadness': 0.08815033, 'Fear': 0.99983466, 'Hate': 1.5800437e-08}\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"print(predict(\"Ami ajke khub voy feel korchi\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:43:18.610975Z","iopub.execute_input":"2025-11-24T18:43:18.611583Z","iopub.status.idle":"2025-11-24T18:43:18.617257Z","shell.execute_reply.started":"2025-11-24T18:43:18.611538Z","shell.execute_reply":"2025-11-24T18:43:18.616699Z"}},"outputs":[{"name":"stdout","text":"{'Love': 1.6210584e-05, 'Joy': 8.5967365e-11, 'Anger': 1.5854556e-07, 'Surprise': 3.180805e-09, 'Sadness': 7.3393833e-09, 'Fear': 1.0, 'Hate': 1.03542265e-10}\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"cm = multilabel_confusion_matrix(labels, (preds > 0.5).astype(int))\n\nfor i, col in enumerate(label_cols):\n    tn, fp, fn, tp = cm[i].ravel()\n    print(f\"\\nLabel: {col}\")\n    print(f\"TP={tp}, FP={fp}, FN={fn}, TN={tn}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:43:42.053111Z","iopub.execute_input":"2025-11-24T18:43:42.053369Z","iopub.status.idle":"2025-11-24T18:43:42.063346Z","shell.execute_reply.started":"2025-11-24T18:43:42.053351Z","shell.execute_reply":"2025-11-24T18:43:42.062734Z"}},"outputs":[{"name":"stdout","text":"\nLabel: Love\nTP=556, FP=283, FN=321, TN=4402\n\nLabel: Joy\nTP=433, FP=330, FN=440, TN=4359\n\nLabel: Anger\nTP=428, FP=362, FN=428, TN=4344\n\nLabel: Surprise\nTP=627, FP=208, FN=200, TN=4527\n\nLabel: Sadness\nTP=421, FP=335, FN=388, TN=4418\n\nLabel: Fear\nTP=693, FP=141, FN=228, TN=4500\n\nLabel: Hate\nTP=538, FP=239, FN=329, TN=4456\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"best_f1 = 0\nbest_t = 0.5\n\nfor t in np.arange(0.1, 0.91, 0.05):\n    y_pred_bin = (preds > t).astype(int)\n    f1 = f1_score(labels, y_pred_bin, average=\"macro\", zero_division=0)\n    if f1 > best_f1:\n        best_f1 = f1\n        best_t = t\n\nprint(\"Best Threshold:\", best_t)\nprint(\"Best Macro-F1:\", best_f1)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-24T18:44:02.513623Z","iopub.execute_input":"2025-11-24T18:44:02.513907Z","iopub.status.idle":"2025-11-24T18:44:02.642604Z","shell.execute_reply.started":"2025-11-24T18:44:02.513888Z","shell.execute_reply":"2025-11-24T18:44:02.642012Z"}},"outputs":[{"name":"stdout","text":"Best Threshold: 0.40000000000000013\nBest Macro-F1: 0.6347376919261603\n","output_type":"stream"}],"execution_count":20}]}