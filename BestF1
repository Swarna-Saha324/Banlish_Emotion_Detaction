{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13802091,"sourceType":"datasetVersion","datasetId":8787854}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-20T13:14:27.848419Z","iopub.execute_input":"2025-11-20T13:14:27.848582Z","iopub.status.idle":"2025-11-20T13:14:29.497218Z","shell.execute_reply.started":"2025-11-20T13:14:27.848566Z","shell.execute_reply":"2025-11-20T13:14:29.496375Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/lastly/collect_preprocessed_dataset.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install transformers==4.45.0 datasets==2.20.0 sentencepiece --quiet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T13:14:32.008894Z","iopub.execute_input":"2025-11-20T13:14:32.009158Z","iopub.status.idle":"2025-11-20T13:14:48.335858Z","shell.execute_reply.started":"2025-11-20T13:14:32.009138Z","shell.execute_reply":"2025-11-20T13:14:48.334956Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m79.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ns3fs 2025.3.0 requires fsspec==2025.3.0.*, but you have fsspec 2024.5.0 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\ntorch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.4 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2024.5.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os, warnings\nos.environ[\"WANDB_DISABLED\"] = \"true\"\nos.environ[\"WANDB_MODE\"] = \"disabled\"\nwarnings.filterwarnings(\"ignore\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T13:15:20.897497Z","iopub.execute_input":"2025-11-20T13:15:20.898168Z","iopub.status.idle":"2025-11-20T13:15:20.901863Z","shell.execute_reply.started":"2025-11-20T13:15:20.898143Z","shell.execute_reply":"2025-11-20T13:15:20.901120Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datasets import Dataset\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T13:16:24.798739Z","iopub.execute_input":"2025-11-20T13:16:24.799762Z","iopub.status.idle":"2025-11-20T13:16:24.804224Z","shell.execute_reply.started":"2025-11-20T13:16:24.799733Z","shell.execute_reply":"2025-11-20T13:16:24.803297Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"emotion_cols = ['Love','Joy','Anger','Surprise','Sadness','Fear','Hate']\n\ndf = pd.read_csv(\"/kaggle/input/lastly/collect_preprocessed_dataset.csv\")\n\n# Keep only necessary columns\ndf = df[['Data'] + emotion_cols]\ndf[\"Data\"] = df[\"Data\"].astype(str)\n\n# Convert labels to float32 for multi-label classification\ndf[emotion_cols] = df[emotion_cols].astype(\"float32\")\ndf[\"labels\"] = df[emotion_cols].values.tolist()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T13:16:30.286282Z","iopub.execute_input":"2025-11-20T13:16:30.286819Z","iopub.status.idle":"2025-11-20T13:16:30.463122Z","shell.execute_reply.started":"2025-11-20T13:16:30.286796Z","shell.execute_reply":"2025-11-20T13:16:30.462489Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, val_df = train_test_split(df, test_size=0.15, random_state=42, shuffle=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T13:16:45.282612Z","iopub.execute_input":"2025-11-20T13:16:45.282924Z","iopub.status.idle":"2025-11-20T13:16:45.307164Z","shell.execute_reply.started":"2025-11-20T13:16:45.282903Z","shell.execute_reply":"2025-11-20T13:16:45.306292Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_ds = Dataset.from_pandas(train_df)\nval_ds   = Dataset.from_pandas(val_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T13:16:53.857284Z","iopub.execute_input":"2025-11-20T13:16:53.858082Z","iopub.status.idle":"2025-11-20T13:16:53.985155Z","shell.execute_reply.started":"2025-11-20T13:16:53.858056Z","shell.execute_reply":"2025-11-20T13:16:53.984357Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"MODEL_NAME = \"xlm-roberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\ndef tokenize(batch):\n    return tokenizer(\n        batch[\"Data\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=128\n    )\n\ntrain_ds = train_ds.map(tokenize, batched=True)\nval_ds   = val_ds.map(tokenize, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T13:17:03.281228Z","iopub.execute_input":"2025-11-20T13:17:03.281810Z","iopub.status.idle":"2025-11-20T13:17:08.779284Z","shell.execute_reply.started":"2025-11-20T13:17:03.281786Z","shell.execute_reply":"2025-11-20T13:17:08.778439Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c1fa12f21014a0aa4941ae7bc895bfc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c5e8d02da894dea99677044cc2d94c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72ee1157ef054a6abf5f7e2ce8cae361"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"228f57b6e9db479590b44f696c01a0e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/23637 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3039b8aca95a46e0b42a9b5e5ec5e31e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4172 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8e1db19dfff497b93b15dd7f27a6c03"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=7,\n    problem_type=\"multi_label_classification\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T13:17:26.058178Z","iopub.execute_input":"2025-11-20T13:17:26.058795Z","iopub.status.idle":"2025-11-20T13:17:29.705028Z","shell.execute_reply.started":"2025-11-20T13:17:26.058770Z","shell.execute_reply":"2025-11-20T13:17:29.704418Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7a3bb6202304111ae0a97508db8d235"}},"metadata":{}},{"name":"stderr","text":"Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def sigmoid(x):\n    return 1 / (1 + np.exp(-x))\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = (sigmoid(logits) > 0.5).astype(np.int32)\n    labels = labels.astype(np.int32)\n\n    acc = accuracy_score(labels, preds)\n    prec = precision_score(labels, preds, average=\"macro\", zero_division=0)\n    rec = recall_score(labels, preds, average=\"macro\", zero_division=0)\n    f1 = f1_score(labels, preds, average=\"macro\", zero_division=0)\n\n    return {\n        \"accuracy\": acc,\n        \"precision_macro\": prec,\n        \"recall_macro\": rec,\n        \"f1_macro\": f1\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T13:17:45.751128Z","iopub.execute_input":"2025-11-20T13:17:45.751907Z","iopub.status.idle":"2025-11-20T13:17:45.757342Z","shell.execute_reply.started":"2025-11-20T13:17:45.751871Z","shell.execute_reply":"2025-11-20T13:17:45.756565Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"/kaggle/working/xlmroberta-emotion\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",           # DO NOT save checkpoints per epoch\n    learning_rate=2e-5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=20,\n    weight_decay=0.01,\n    logging_strategy=\"epoch\",     # logs metrics every epoch\n    report_to=\"none\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T13:18:02.825153Z","iopub.execute_input":"2025-11-20T13:18:02.825856Z","iopub.status.idle":"2025-11-20T13:18:02.860101Z","shell.execute_reply.started":"2025-11-20T13:18:02.825833Z","shell.execute_reply":"2025-11-20T13:18:02.859567Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"/kaggle/working/xlmroberta-emotion\",\n    evaluation_strategy=\"epoch\",\n    logging_strategy=\"epoch\",      # log metrics every epoch\n    save_strategy=\"no\",            # disk-safe\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=20,\n    learning_rate=2e-5,\n    weight_decay=0.01,\n    report_to=\"none\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T14:08:42.748560Z","iopub.execute_input":"2025-11-20T14:08:42.749115Z","iopub.status.idle":"2025-11-20T14:08:42.782765Z","shell.execute_reply.started":"2025-11-20T14:08:42.749089Z","shell.execute_reply":"2025-11-20T14:08:42.781970Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"from transformers import TrainerCallback\n\nclass MetricsLoggerCallback(TrainerCallback):\n    def on_epoch_end(self, args, state, control, logs=None, **kwargs):\n        if logs is not None:\n            print(f\"Epoch {state.epoch}:\")\n            print({k: v for k, v in logs.items() if k not in ['step', 'epoch']})\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T14:08:46.667029Z","iopub.execute_input":"2025-11-20T14:08:46.667703Z","iopub.status.idle":"2025-11-20T14:08:46.671810Z","shell.execute_reply.started":"2025-11-20T14:08:46.667683Z","shell.execute_reply":"2025-11-20T14:08:46.671194Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"remove_cols = ['Data'] + emotion_cols\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_ds.remove_columns(remove_cols),\n    eval_dataset=val_ds.remove_columns(remove_cols),\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n    callbacks=[MetricsLoggerCallback]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T14:08:51.850341Z","iopub.execute_input":"2025-11-20T14:08:51.850604Z","iopub.status.idle":"2025-11-20T14:08:51.866383Z","shell.execute_reply.started":"2025-11-20T14:08:51.850585Z","shell.execute_reply":"2025-11-20T14:08:51.865604Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"def predict(text):\n    enc = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=128)\n    outputs = model(**enc)\n    probs = sigmoid(outputs.logits.detach().numpy())[0]\n    return dict(zip(emotion_cols, probs))\n\npredict(\"Ami onek upset, mon kharap.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-20T14:08:55.997825Z","iopub.execute_input":"2025-11-20T14:08:55.998100Z","iopub.status.idle":"2025-11-20T18:11:56.161473Z","shell.execute_reply.started":"2025-11-20T14:08:55.998081Z","shell.execute_reply":"2025-11-20T18:11:56.160575Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='29560' max='29560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [29560/29560 4:02:59, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>Precision Macro</th>\n      <th>Recall Macro</th>\n      <th>F1 Macro</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.209900</td>\n      <td>0.277944</td>\n      <td>0.534036</td>\n      <td>0.676855</td>\n      <td>0.582602</td>\n      <td>0.615976</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.176300</td>\n      <td>0.267017</td>\n      <td>0.551774</td>\n      <td>0.681356</td>\n      <td>0.614281</td>\n      <td>0.643322</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.161100</td>\n      <td>0.276121</td>\n      <td>0.573346</td>\n      <td>0.674891</td>\n      <td>0.647761</td>\n      <td>0.658254</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.157200</td>\n      <td>0.273524</td>\n      <td>0.582694</td>\n      <td>0.699394</td>\n      <td>0.635036</td>\n      <td>0.658093</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.146400</td>\n      <td>0.251630</td>\n      <td>0.596117</td>\n      <td>0.718549</td>\n      <td>0.656977</td>\n      <td>0.682553</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.127800</td>\n      <td>0.278718</td>\n      <td>0.616251</td>\n      <td>0.706079</td>\n      <td>0.672970</td>\n      <td>0.687078</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.109800</td>\n      <td>0.290181</td>\n      <td>0.614334</td>\n      <td>0.701426</td>\n      <td>0.679243</td>\n      <td>0.688694</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.096200</td>\n      <td>0.301196</td>\n      <td>0.625120</td>\n      <td>0.705110</td>\n      <td>0.679336</td>\n      <td>0.688399</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.082100</td>\n      <td>0.321425</td>\n      <td>0.622483</td>\n      <td>0.704500</td>\n      <td>0.681731</td>\n      <td>0.691189</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.072000</td>\n      <td>0.328792</td>\n      <td>0.628476</td>\n      <td>0.707020</td>\n      <td>0.695649</td>\n      <td>0.700215</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.062400</td>\n      <td>0.334368</td>\n      <td>0.632071</td>\n      <td>0.703228</td>\n      <td>0.707023</td>\n      <td>0.704062</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.054700</td>\n      <td>0.365293</td>\n      <td>0.628476</td>\n      <td>0.704271</td>\n      <td>0.685937</td>\n      <td>0.692062</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.048200</td>\n      <td>0.365164</td>\n      <td>0.636146</td>\n      <td>0.702434</td>\n      <td>0.724448</td>\n      <td>0.712423</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.042000</td>\n      <td>0.387083</td>\n      <td>0.638543</td>\n      <td>0.706454</td>\n      <td>0.709591</td>\n      <td>0.706779</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.034500</td>\n      <td>0.397884</td>\n      <td>0.644535</td>\n      <td>0.712424</td>\n      <td>0.711191</td>\n      <td>0.711283</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.030200</td>\n      <td>0.402333</td>\n      <td>0.647891</td>\n      <td>0.714303</td>\n      <td>0.712406</td>\n      <td>0.712782</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.026500</td>\n      <td>0.415541</td>\n      <td>0.644295</td>\n      <td>0.711001</td>\n      <td>0.713189</td>\n      <td>0.711203</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.024500</td>\n      <td>0.424994</td>\n      <td>0.645014</td>\n      <td>0.709027</td>\n      <td>0.713756</td>\n      <td>0.711142</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.020200</td>\n      <td>0.428180</td>\n      <td>0.649089</td>\n      <td>0.712534</td>\n      <td>0.714008</td>\n      <td>0.712717</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.018700</td>\n      <td>0.431417</td>\n      <td>0.647891</td>\n      <td>0.711463</td>\n      <td>0.712830</td>\n      <td>0.711471</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=29560, training_loss=0.08503085518399497, metrics={'train_runtime': 14579.5521, 'train_samples_per_second': 32.425, 'train_steps_per_second': 2.027, 'total_flos': 3.1097176060032e+16, 'train_loss': 0.08503085518399497, 'epoch': 20.0})"},"metadata":{}}],"execution_count":26}]}