{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13802091,"sourceType":"datasetVersion","datasetId":8787854}],"dockerImageVersionId":31240,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:51:21.919382Z","iopub.execute_input":"2025-12-19T04:51:21.919581Z","iopub.status.idle":"2025-12-19T04:51:23.472449Z","shell.execute_reply.started":"2025-12-19T04:51:21.919565Z","shell.execute_reply":"2025-12-19T04:51:23.471648Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/lastly/collect_preprocessed_dataset.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\n\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import (\n    f1_score, precision_score,\n    recall_score, accuracy_score, hamming_loss\n)\n\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:52:11.766019Z","iopub.execute_input":"2025-12-19T04:52:11.766867Z","iopub.status.idle":"2025-12-19T04:52:11.770848Z","shell.execute_reply.started":"2025-12-19T04:52:11.766840Z","shell.execute_reply":"2025-12-19T04:52:11.770083Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/lastly/collect_preprocessed_dataset.csv\")\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:53:31.318216Z","iopub.execute_input":"2025-12-19T04:53:31.318777Z","iopub.status.idle":"2025-12-19T04:53:31.379624Z","shell.execute_reply.started":"2025-12-19T04:53:31.318753Z","shell.execute_reply":"2025-12-19T04:53:31.379040Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"df.columns\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:53:41.856888Z","iopub.execute_input":"2025-12-19T04:53:41.857135Z","iopub.status.idle":"2025-12-19T04:53:41.862755Z","shell.execute_reply.started":"2025-12-19T04:53:41.857119Z","shell.execute_reply":"2025-12-19T04:53:41.862205Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"Index(['Data', 'Love', 'Joy', 'Anger', 'Surprise', 'Sadness', 'Fear', 'Hate',\n       'topic', 'Domain'],\n      dtype='object')"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"emotion_cols = [\"Love\",\"Sadness\",\"Anger\",\"Surprise\",\"Fear\",\"Joy\",\"Hate\"]\n\ndf = df[[\"Data\"] + emotion_cols]\ndf.dropna(inplace=True)\ndf = df.sample(frac=1, random_state=42).reset_index(drop=True)\n\nprint(\"Dataset shape:\", df.shape)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:54:02.889740Z","iopub.execute_input":"2025-12-19T04:54:02.890312Z","iopub.status.idle":"2025-12-19T04:54:02.922629Z","shell.execute_reply.started":"2025-12-19T04:54:02.890283Z","shell.execute_reply":"2025-12-19T04:54:02.922095Z"}},"outputs":[{"name":"stdout","text":"Dataset shape: (27808, 8)\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                Data  Love  Sadness  Anger  \\\n0                       shitkale pampers pore ghumai     0        0      0   \n1                           ekta dokane 40 lakh taka     0        0      0   \n2  ami ekta aghatojnit smriti somporke obogoto ho...     0        0      0   \n3            tuder opor hobe gojob na kar opore hobe     0        0      0   \n4  update deoyar por onek valo hoye gese godi 100...     1        0      0   \n\n   Surprise  Fear  Joy  Hate  \n0         1     0    0     0  \n1         0     0    0     1  \n2         0     1    0     0  \n3         0     1    0     0  \n4         0     0    0     0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Data</th>\n      <th>Love</th>\n      <th>Sadness</th>\n      <th>Anger</th>\n      <th>Surprise</th>\n      <th>Fear</th>\n      <th>Joy</th>\n      <th>Hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>shitkale pampers pore ghumai</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ekta dokane 40 lakh taka</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ami ekta aghatojnit smriti somporke obogoto ho...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tuder opor hobe gojob na kar opore hobe</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>update deoyar por onek valo hoye gese godi 100...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"train_df, temp_df = train_test_split(df, test_size=0.2, random_state=42)\nval_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:54:15.263750Z","iopub.execute_input":"2025-12-19T04:54:15.264443Z","iopub.status.idle":"2025-12-19T04:54:15.274334Z","shell.execute_reply.started":"2025-12-19T04:54:15.264415Z","shell.execute_reply":"2025-12-19T04:54:15.273751Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class EmotionDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len=128):\n        self.texts = df[\"Data\"].tolist()\n        self.labels = df[emotion_cols].values\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        enc = self.tokenizer(\n            self.texts[idx],\n            truncation=True,\n            padding=\"max_length\",\n            max_length=self.max_len,\n            return_tensors=\"pt\"\n        )\n        return {\n            \"input_ids\": enc[\"input_ids\"].squeeze(),\n            \"attention_mask\": enc[\"attention_mask\"].squeeze(),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.float)\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:54:25.699480Z","iopub.execute_input":"2025-12-19T04:54:25.700034Z","iopub.status.idle":"2025-12-19T04:54:25.705374Z","shell.execute_reply.started":"2025-12-19T04:54:25.700008Z","shell.execute_reply":"2025-12-19T04:54:25.704738Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"MODEL_NAME = \"csebuetnlp/banglishbert\"\ntokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n\ntrain_ds = EmotionDataset(train_df, tokenizer)\nval_ds   = EmotionDataset(val_df, tokenizer)\ntest_ds  = EmotionDataset(test_df, tokenizer)\n\ntrain_loader = DataLoader(train_ds, batch_size=8, shuffle=True)\nval_loader   = DataLoader(val_ds, batch_size=8)\ntest_loader  = DataLoader(test_ds, batch_size=8)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:54:37.949012Z","iopub.execute_input":"2025-12-19T04:54:37.949303Z","iopub.status.idle":"2025-12-19T04:54:39.411981Z","shell.execute_reply.started":"2025-12-19T04:54:37.949281Z","shell.execute_reply":"2025-12-19T04:54:39.411368Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a35de19017c49db867a69c3e4971694"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/874 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fcffa207919843c89ce55d4c6d03458d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"63cdbbf71ba14559b16a1876b1c80906"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e00ad88c840c41d6ad88e0d4904bc69d"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = AutoModelForSequenceClassification.from_pretrained(\n    MODEL_NAME,\n    num_labels=7,\n    problem_type=\"multi_label_classification\"\n).to(device)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:55:03.937542Z","iopub.execute_input":"2025-12-19T04:55:03.937860Z","iopub.status.idle":"2025-12-19T04:55:27.399115Z","shell.execute_reply.started":"2025-12-19T04:55:03.937808Z","shell.execute_reply":"2025-12-19T04:55:27.398248Z"}},"outputs":[{"name":"stderr","text":"2025-12-19 04:55:07.481247: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766120107.670537      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766120107.720321      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c24f2b4dc53a46c0809289a2d29c0eb0"}},"metadata":{}},{"name":"stderr","text":"Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at csebuetnlp/banglishbert and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f151062a145418ea0fbbe3aa0fabc83"}},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(\n    model.parameters(),\n    lr=2e-5,          # BanglishBERT sweet spot\n    weight_decay=0.01\n)\n\ncriterion = torch.nn.BCEWithLogitsLoss()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:55:41.817122Z","iopub.execute_input":"2025-12-19T04:55:41.818373Z","iopub.status.idle":"2025-12-19T04:55:41.822681Z","shell.execute_reply.started":"2025-12-19T04:55:41.818329Z","shell.execute_reply":"2025-12-19T04:55:41.822030Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def train_epoch(model, loader):\n    model.train()\n    total_loss = 0\n\n    for batch in tqdm(loader):\n        optimizer.zero_grad()\n\n        input_ids = batch[\"input_ids\"].to(device)\n        mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        outputs = model(input_ids, attention_mask=mask)\n        loss = criterion(outputs.logits, labels)\n\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:56:22.182666Z","iopub.execute_input":"2025-12-19T04:56:22.183401Z","iopub.status.idle":"2025-12-19T04:56:22.188051Z","shell.execute_reply.started":"2025-12-19T04:56:22.183372Z","shell.execute_reply":"2025-12-19T04:56:22.187380Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def evaluate(model, loader):\n    model.eval()\n    all_preds, all_labels = [], []\n\n    with torch.no_grad():\n        for batch in loader:\n            input_ids = batch[\"input_ids\"].to(device)\n            mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"labels\"].cpu().numpy()\n\n            logits = model(input_ids, attention_mask=mask).logits\n            probs = torch.sigmoid(logits).cpu().numpy()\n            preds = (probs > 0.5).astype(int)\n\n            all_preds.append(preds)\n            all_labels.append(labels)\n\n    y_pred = np.vstack(all_preds)\n    y_true = np.vstack(all_labels)\n\n    return {\n        \"subset_accuracy\": accuracy_score(y_true, y_pred),\n        \"hamming_accuracy\": 1 - hamming_loss(y_true, y_pred),\n        \"macro_f1\": f1_score(y_true, y_pred, average=\"macro\"),\n        \"precision\": precision_score(y_true, y_pred, average=\"macro\"),\n        \"recall\": recall_score(y_true, y_pred, average=\"macro\"),\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T04:57:10.558688Z","iopub.execute_input":"2025-12-19T04:57:10.559524Z","iopub.status.idle":"2025-12-19T04:57:10.565009Z","shell.execute_reply.started":"2025-12-19T04:57:10.559494Z","shell.execute_reply":"2025-12-19T04:57:10.564302Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"for epoch in range(8):\n    loss = train_epoch(model, train_loader)\n    metrics = evaluate(model, val_loader)\n\n    print(f\"\\nEpoch {epoch+1}\")\n    print(\"Train Loss:\", loss)\n    print(metrics)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T05:32:18.995722Z","iopub.execute_input":"2025-12-19T05:32:18.996248Z","iopub.status.idle":"2025-12-19T06:47:18.824397Z","shell.execute_reply.started":"2025-12-19T05:32:18.996228Z","shell.execute_reply":"2025-12-19T06:47:18.823668Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 2781/2781 [09:01<00:00,  5.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1\nTrain Loss: 0.14656824647311317\n{'subset_accuracy': 0.5767709457029845, 'hamming_accuracy': 0.8999332203215699, 'macro_f1': 0.6632221516395489, 'precision': 0.695605035804963, 'recall': 0.6392820382233195}\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2781/2781 [09:02<00:00,  5.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2\nTrain Loss: 0.11917847162280037\n{'subset_accuracy': 0.5875584322186264, 'hamming_accuracy': 0.9048646427287204, 'macro_f1': 0.6754138146671644, 'precision': 0.7143239815441973, 'recall': 0.6424257450080458}\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2781/2781 [09:01<00:00,  5.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3\nTrain Loss: 0.09746176513037164\n{'subset_accuracy': 0.5886371808701906, 'hamming_accuracy': 0.8989058406534135, 'macro_f1': 0.6648269176261193, 'precision': 0.6955059417125743, 'recall': 0.6458330592949547}\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2781/2781 [09:01<00:00,  5.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4\nTrain Loss: 0.07965243684247816\n{'subset_accuracy': 0.594750089895721, 'hamming_accuracy': 0.8991626855704525, 'macro_f1': 0.6686707910858994, 'precision': 0.6894773362577, 'recall': 0.6538641357148883}\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2781/2781 [09:02<00:00,  5.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5\nTrain Loss: 0.0662141822201308\n{'subset_accuracy': 0.6120100683207479, 'hamming_accuracy': 0.905840653413469, 'macro_f1': 0.6867701694242176, 'precision': 0.7049678934346423, 'recall': 0.674146991078706}\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2781/2781 [09:01<00:00,  5.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6\nTrain Loss: 0.05906678329279505\n{'subset_accuracy': 0.6105717367853291, 'hamming_accuracy': 0.9033749422098937, 'macro_f1': 0.674719093440743, 'precision': 0.7025253461523301, 'recall': 0.6525204247911536}\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2781/2781 [09:01<00:00,  5.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7\nTrain Loss: 0.048590290725515156\n{'subset_accuracy': 0.6073354908306364, 'hamming_accuracy': 0.9019366106744747, 'macro_f1': 0.6888441509541671, 'precision': 0.6959301924971752, 'recall': 0.6875918220513102}\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2781/2781 [09:02<00:00,  5.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8\nTrain Loss: 0.044456189430616154\n{'subset_accuracy': 0.6130888169723121, 'hamming_accuracy': 0.9023989315251452, 'macro_f1': 0.6865134277730831, 'precision': 0.6949597926762773, 'recall': 0.6800154952358473}\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"SAVE_PATH = \"/kaggle/working/banglishBert_model\"\n\nmodel.save_pretrained(SAVE_PATH)\ntokenizer.save_pretrained(SAVE_PATH)\n\n# Save thresholds\nnp.save(f\"{SAVE_PATH}/thresholds.npy\", np.array(best_thresholds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:57:58.106948Z","iopub.execute_input":"2025-12-19T06:57:58.107593Z","iopub.status.idle":"2025-12-19T06:57:58.914630Z","shell.execute_reply.started":"2025-12-19T06:57:58.107568Z","shell.execute_reply":"2025-12-19T06:57:58.913809Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_47/1760112010.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Save thresholds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{SAVE_PATH}/thresholds.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_thresholds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'best_thresholds' is not defined"],"ename":"NameError","evalue":"name 'best_thresholds' is not defined","output_type":"error"}],"execution_count":20},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import f1_score\n\ndef tune_thresholds(y_true, y_probs):\n    best_thresholds = []\n\n    for i in range(y_true.shape[1]):\n        best_f1 = 0\n        best_t = 0.5\n\n        for t in np.arange(0.1, 0.9, 0.05):\n            preds = (y_probs[:, i] > t).astype(int)\n            f1 = f1_score(y_true[:, i], preds)\n\n            if f1 > best_f1:\n                best_f1 = f1\n                best_t = t\n\n        best_thresholds.append(best_t)\n\n    return best_thresholds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:58:49.704282Z","iopub.execute_input":"2025-12-19T06:58:49.704958Z","iopub.status.idle":"2025-12-19T06:58:49.709547Z","shell.execute_reply.started":"2025-12-19T06:58:49.704933Z","shell.execute_reply":"2025-12-19T06:58:49.708928Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def apply_thresholds(probs, thresholds):\n    preds = np.zeros_like(probs)\n\n    for i, t in enumerate(thresholds):\n        preds[:, i] = (probs[:, i] > t).astype(int)\n\n    return preds\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:59:16.183235Z","iopub.execute_input":"2025-12-19T06:59:16.183481Z","iopub.status.idle":"2025-12-19T06:59:16.187190Z","shell.execute_reply.started":"2025-12-19T06:59:16.183462Z","shell.execute_reply":"2025-12-19T06:59:16.186553Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# After validation\nval_probs, val_labels = [], []\n\nmodel.eval()\nwith torch.no_grad():\n    for batch in val_loader:\n        ids = batch[\"input_ids\"].to(device)\n        mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].cpu().numpy()\n\n        logits = model(ids, attention_mask=mask).logits\n        probs = torch.sigmoid(logits).cpu().numpy()\n\n        val_probs.append(probs)\n        val_labels.append(labels)\n\nval_probs = np.vstack(val_probs)\nval_labels = np.vstack(val_labels)\n\nbest_thresholds = tune_thresholds(val_labels, val_probs)\nprint(\"Best thresholds:\", best_thresholds)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T06:59:34.394261Z","iopub.execute_input":"2025-12-19T06:59:34.394548Z","iopub.status.idle":"2025-12-19T06:59:55.286321Z","shell.execute_reply.started":"2025-12-19T06:59:34.394528Z","shell.execute_reply":"2025-12-19T06:59:55.285597Z"}},"outputs":[{"name":"stdout","text":"Best thresholds: [0.6000000000000002, 0.30000000000000004, 0.5500000000000002, 0.8000000000000002, 0.8000000000000002, 0.6000000000000002, 0.20000000000000004]\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"test_probs, test_labels = [], []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        ids = batch[\"input_ids\"].to(device)\n        mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].cpu().numpy()\n\n        logits = model(ids, attention_mask=mask).logits\n        probs = torch.sigmoid(logits).cpu().numpy()\n\n        test_probs.append(probs)\n        test_labels.append(labels)\n\ntest_probs = np.vstack(test_probs)\ntest_labels = np.vstack(test_labels)\n\ntest_preds = apply_thresholds(test_probs, best_thresholds)\n\nprint(\"Macro F1:\", f1_score(test_labels, test_preds, average=\"macro\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T07:00:18.505267Z","iopub.execute_input":"2025-12-19T07:00:18.505905Z","iopub.status.idle":"2025-12-19T07:00:39.472008Z","shell.execute_reply.started":"2025-12-19T07:00:18.505881Z","shell.execute_reply":"2025-12-19T07:00:39.471391Z"}},"outputs":[{"name":"stdout","text":"Macro F1: 0.6804339120819751\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"SAVE_PATH = \"/kaggle/working/banglishBert_model\"\n\nmodel.save_pretrained(SAVE_PATH)\ntokenizer.save_pretrained(SAVE_PATH)\n\n# Save thresholds\nnp.save(f\"{SAVE_PATH}/thresholds.npy\", np.array(best_thresholds))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T07:01:06.725554Z","iopub.execute_input":"2025-12-19T07:01:06.726246Z","iopub.status.idle":"2025-12-19T07:01:07.826244Z","shell.execute_reply.started":"2025-12-19T07:01:06.726220Z","shell.execute_reply":"2025-12-19T07:01:07.825685Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\n\nmodel = AutoModelForSequenceClassification.from_pretrained(SAVE_PATH).to(device)\ntokenizer = AutoTokenizer.from_pretrained(SAVE_PATH)\n\nthresholds = np.load(f\"{SAVE_PATH}/thresholds.npy\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T07:01:23.286613Z","iopub.execute_input":"2025-12-19T07:01:23.286983Z","iopub.status.idle":"2025-12-19T07:01:23.529238Z","shell.execute_reply.started":"2025-12-19T07:01:23.286959Z","shell.execute_reply":"2025-12-19T07:01:23.528676Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"emotion_cols = [\"Love\",\"Sad\",\"Angry\",\"Surprise\",\"Fear\",\"Joy\",\"Hate\"]\n\ndef predict_emotion(text):\n    enc = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        padding=True,\n        max_length=128\n    ).to(device)\n\n    with torch.no_grad():\n        logits = model(**enc).logits\n        probs = torch.sigmoid(logits)[0].cpu().numpy()\n\n    results = []\n    for emo, p, t in zip(emotion_cols, probs, thresholds):\n        if p > t:\n            results.append((emo, round(float(p), 3)))\n\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T07:01:40.521200Z","iopub.execute_input":"2025-12-19T07:01:40.521757Z","iopub.status.idle":"2025-12-19T07:01:40.526871Z","shell.execute_reply.started":"2025-12-19T07:01:40.521735Z","shell.execute_reply":"2025-12-19T07:01:40.526208Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"predict_emotion(\"ami onek khushi but ektu voy lagche\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T07:04:31.236396Z","iopub.execute_input":"2025-12-19T07:04:31.237071Z","iopub.status.idle":"2025-12-19T07:04:31.264251Z","shell.execute_reply.started":"2025-12-19T07:04:31.237045Z","shell.execute_reply":"2025-12-19T07:04:31.263688Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"[('Fear', 1.0)]"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"def predict_topk(text, k=3):\n    model.eval()\n\n    inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        padding=True,\n        max_length=128\n    ).to(device)\n\n    with torch.no_grad():\n        logits = model(**inputs).logits\n        probs = torch.sigmoid(logits)[0].cpu().numpy()\n\n    scores = list(zip(emotion_cols, probs))\n    scores.sort(key=lambda x: x[1], reverse=True)\n\n    return scores[:k]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T07:06:40.598399Z","iopub.execute_input":"2025-12-19T07:06:40.598678Z","iopub.status.idle":"2025-12-19T07:06:40.603865Z","shell.execute_reply.started":"2025-12-19T07:06:40.598657Z","shell.execute_reply":"2025-12-19T07:06:40.603056Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"predict_topk(\"ami onek khushi but ektu voy lagche\", k=3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T07:06:58.892683Z","iopub.execute_input":"2025-12-19T07:06:58.892957Z","iopub.status.idle":"2025-12-19T07:06:58.911963Z","shell.execute_reply.started":"2025-12-19T07:06:58.892936Z","shell.execute_reply":"2025-12-19T07:06:58.911425Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"[('Fear', 0.99963), ('Sad', 0.00045022933), ('Angry', 0.0001944166)]"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"def predict_threshold(text):\n    model.eval()\n\n    inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        padding=True,\n        max_length=128\n    ).to(device)\n\n    with torch.no_grad():\n        logits = model(**inputs).logits\n        probs = torch.sigmoid(logits)[0].cpu().numpy()\n\n    results = []\n    for emo, p in zip(emotion_cols, probs):\n        if p >= thresholds[emo]:\n            results.append((emo, round(float(p), 3)))\n\n    if not results:\n        # fallback\n        top_idx = np.argmax(probs)\n        results.append((emotion_cols[top_idx], round(float(probs[top_idx]), 3)))\n\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T07:27:29.632081Z","iopub.execute_input":"2025-12-19T07:27:29.632805Z","iopub.status.idle":"2025-12-19T07:27:29.638201Z","shell.execute_reply.started":"2025-12-19T07:27:29.632777Z","shell.execute_reply":"2025-12-19T07:27:29.637501Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"predict_topk(\"ami onek khushi but ektu voy lagche\", k=3)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-19T07:27:39.875997Z","iopub.execute_input":"2025-12-19T07:27:39.876581Z","iopub.status.idle":"2025-12-19T07:27:39.895318Z","shell.execute_reply.started":"2025-12-19T07:27:39.876555Z","shell.execute_reply":"2025-12-19T07:27:39.894647Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"[('Fear', 0.99963), ('Sad', 0.00045022933), ('Angry', 0.0001944166)]"},"metadata":{}}],"execution_count":33}]}
