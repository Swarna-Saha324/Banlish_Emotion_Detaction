{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13802091,"sourceType":"datasetVersion","datasetId":8787854}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:35:43.277986Z","iopub.execute_input":"2025-11-23T19:35:43.278267Z","iopub.status.idle":"2025-11-23T19:35:45.025189Z","shell.execute_reply.started":"2025-11-23T19:35:43.278208Z","shell.execute_reply":"2025-11-23T19:35:45.024454Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/lastly/collect_preprocessed_dataset.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:35:45.026606Z","iopub.execute_input":"2025-11-23T19:35:45.026935Z","iopub.status.idle":"2025-11-23T19:35:49.530771Z","shell.execute_reply.started":"2025-11-23T19:35:45.026917Z","shell.execute_reply":"2025-11-23T19:35:49.529861Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.20.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.2.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.10.5)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import classification_report, accuracy_score\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:35:49.531867Z","iopub.execute_input":"2025-11-23T19:35:49.532642Z","iopub.status.idle":"2025-11-23T19:36:00.592530Z","shell.execute_reply.started":"2025-11-23T19:35:49.532608Z","shell.execute_reply":"2025-11-23T19:36:00.591946Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/lastly/collect_preprocessed_dataset.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:36:00.593217Z","iopub.execute_input":"2025-11-23T19:36:00.593529Z","iopub.status.idle":"2025-11-23T19:36:00.744679Z","shell.execute_reply.started":"2025-11-23T19:36:00.593513Z","shell.execute_reply":"2025-11-23T19:36:00.744085Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"emotion_cols = ['Love','Joy','Anger','Surprise','Sadness','Fear','Hate']\n\ndef get_label(row):\n    for col in emotion_cols:\n        if row[col] == 1:\n            return col\n    return None\n\ndf['Label'] = df.apply(get_label, axis=1)\ndf = df.dropna(subset=['Label']).reset_index(drop=True)\ndf = df[['Data','Label']]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:36:00.746515Z","iopub.execute_input":"2025-11-23T19:36:00.746754Z","iopub.status.idle":"2025-11-23T19:36:01.037021Z","shell.execute_reply.started":"2025-11-23T19:36:00.746739Z","shell.execute_reply":"2025-11-23T19:36:01.036169Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"le = LabelEncoder()\ndf['label_id'] = le.fit_transform(df['Label'])\nnum_labels = df['label_id'].nunique()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:36:01.037846Z","iopub.execute_input":"2025-11-23T19:36:01.038072Z","iopub.status.idle":"2025-11-23T19:36:01.049682Z","shell.execute_reply.started":"2025-11-23T19:36:01.038055Z","shell.execute_reply":"2025-11-23T19:36:01.048958Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"df['Data'] = df['Data'].astype(str).fillna(\"\")\ndf['label_id'] = df['label_id'].astype(int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:36:01.050532Z","iopub.execute_input":"2025-11-23T19:36:01.050799Z","iopub.status.idle":"2025-11-23T19:36:01.066416Z","shell.execute_reply.started":"2025-11-23T19:36:01.050781Z","shell.execute_reply":"2025-11-23T19:36:01.065807Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"train_texts, test_texts, train_labels, test_labels = train_test_split(\n    df['Data'],\n    df['label_id'],\n    test_size=0.15,\n    random_state=42,\n    stratify=df['label_id']\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:36:01.067203Z","iopub.execute_input":"2025-11-23T19:36:01.067637Z","iopub.status.idle":"2025-11-23T19:36:01.095312Z","shell.execute_reply.started":"2025-11-23T19:36:01.067618Z","shell.execute_reply":"2025-11-23T19:36:01.094473Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"model_name = \"distilbert-base-multilingual-cased\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:36:01.096277Z","iopub.execute_input":"2025-11-23T19:36:01.096618Z","iopub.status.idle":"2025-11-23T19:36:02.696681Z","shell.execute_reply.started":"2025-11-23T19:36:01.096592Z","shell.execute_reply":"2025-11-23T19:36:02.695859Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd83a59618e84e5ea3c52ca75dca12a9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/466 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc48790f1cba40fc8e34f336a865d349"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf4942b9fe4a493c95d0d2d4354da49d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae64ba4b43db48b49dcbf14d90e5f6af"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"class EmotionDataset(Dataset):\n    def __init__(self, texts, labels):\n        self.texts = texts.tolist()\n        self.labels = labels.tolist()\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        enc = tokenizer(\n            self.texts[idx],\n            truncation=True,\n            padding=\"max_length\",\n            max_length=80,\n            return_tensors=\"pt\"\n        )\n        return {\n            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long)\n        }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:36:02.697537Z","iopub.execute_input":"2025-11-23T19:36:02.697806Z","iopub.status.idle":"2025-11-23T19:36:02.703147Z","shell.execute_reply.started":"2025-11-23T19:36:02.697777Z","shell.execute_reply":"2025-11-23T19:36:02.702442Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_dataset = EmotionDataset(train_texts, train_labels)\ntest_dataset = EmotionDataset(test_texts, test_labels)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=16)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:36:02.703915Z","iopub.execute_input":"2025-11-23T19:36:02.704152Z","iopub.status.idle":"2025-11-23T19:36:02.723740Z","shell.execute_reply.started":"2025-11-23T19:36:02.704131Z","shell.execute_reply":"2025-11-23T19:36:02.722991Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    model_name,\n    num_labels=num_labels\n)\nmodel = model.cuda()   # Use GPU\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:36:02.724504Z","iopub.execute_input":"2025-11-23T19:36:02.724788Z","iopub.status.idle":"2025-11-23T19:36:27.092556Z","shell.execute_reply.started":"2025-11-23T19:36:02.724761Z","shell.execute_reply":"2025-11-23T19:36:27.091953Z"}},"outputs":[{"name":"stderr","text":"2025-11-23 19:36:06.331229: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763926566.530071      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763926566.591932      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/542M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"829610b1d4df4949a0a1557ddae25a02"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n\nfor epoch in range(8):\n    model.train()\n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].cuda()\n        attention_mask = batch[\"attention_mask\"].cuda()\n        labels = batch[\"labels\"].cuda()\n\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels\n        )\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n    print(f\"Epoch {epoch+1} Loss:\", loss.item())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T19:36:27.093224Z","iopub.execute_input":"2025-11-23T19:36:27.093659Z","iopub.status.idle":"2025-11-23T20:05:12.852688Z","shell.execute_reply.started":"2025-11-23T19:36:27.093643Z","shell.execute_reply":"2025-11-23T20:05:12.852032Z"}},"outputs":[{"name":"stdout","text":"Epoch 1 Loss: 1.3751447200775146\nEpoch 2 Loss: 1.7345250844955444\nEpoch 3 Loss: 1.2367184162139893\nEpoch 4 Loss: 0.5791839361190796\nEpoch 5 Loss: 0.42949920892715454\nEpoch 6 Loss: 0.07364986836910248\nEpoch 7 Loss: 0.62641841173172\nEpoch 8 Loss: 0.13466523587703705\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"model.eval()\npreds = []\ntrue = []\n\nwith torch.no_grad():\n    for batch in test_loader:\n        input_ids = batch[\"input_ids\"].cuda()\n        attention_mask = batch[\"attention_mask\"].cuda()\n        labels = batch[\"labels\"].cuda()\n\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask\n        )\n\n        pred = torch.argmax(outputs.logits, dim=1)\n        preds.extend(pred.cpu().numpy())\n        true.extend(labels.cpu().numpy())\n\nprint(\"Accuracy:\", accuracy_score(true, preds))\nprint(classification_report(true, preds, target_names=le.classes_))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T20:05:12.855020Z","iopub.execute_input":"2025-11-23T20:05:12.855235Z","iopub.status.idle":"2025-11-23T20:05:23.323292Z","shell.execute_reply.started":"2025-11-23T20:05:12.855218Z","shell.execute_reply":"2025-11-23T20:05:23.322502Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.6631197097944377\n              precision    recall  f1-score   support\n\n       Anger       0.54      0.64      0.58       639\n        Fear       0.80      0.86      0.83       614\n        Hate       0.65      0.62      0.63       566\n         Joy       0.65      0.56      0.60       593\n        Love       0.73      0.69      0.71       650\n     Sadness       0.63      0.54      0.58       551\n    Surprise       0.65      0.73      0.69       522\n\n    accuracy                           0.66      4135\n   macro avg       0.66      0.66      0.66      4135\nweighted avg       0.66      0.66      0.66      4135\n\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n\nfor epoch in range(8):\n    model.train()\n    \n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].cuda()\n        attention_mask = batch[\"attention_mask\"].cuda()\n        labels = batch[\"labels\"].cuda()\n\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels\n        )\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n    print(f\"\\n======== Epoch {epoch+1} Training Loss: {loss.item():.4f} ========\")\n\n    # -------------------------------\n    # ðŸ”¥ Evaluate after each epoch\n    # -------------------------------\n    model.eval()\n    epoch_preds = []\n    epoch_true = []\n\n    with torch.no_grad():\n        for batch in test_loader:\n            input_ids = batch[\"input_ids\"].cuda()\n            attention_mask = batch[\"attention_mask\"].cuda()\n            labels = batch[\"labels\"].cuda()\n\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask\n            )\n\n            pred = torch.argmax(outputs.logits, dim=1)\n\n            epoch_preds.extend(pred.cpu().numpy())\n            epoch_true.extend(labels.cpu().numpy())\n\n    # Metrics\n    acc = accuracy_score(epoch_true, epoch_preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        epoch_true, epoch_preds, average='weighted', zero_division=0\n    )\n\n    print(f\"Epoch {epoch+1} Accuracy:  {acc:.4f}\")\n    print(f\"Epoch {epoch+1} Precision: {precision:.4f}\")\n    print(f\"Epoch {epoch+1} Recall:    {recall:.4f}\")\n    print(f\"Epoch {epoch+1} F1-score:  {f1:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T20:07:43.156254Z","iopub.execute_input":"2025-11-23T20:07:43.156572Z","iopub.status.idle":"2025-11-23T20:38:04.053245Z","shell.execute_reply.started":"2025-11-23T20:07:43.156551Z","shell.execute_reply":"2025-11-23T20:38:04.052381Z"}},"outputs":[{"name":"stdout","text":"\n======== Epoch 1 Training Loss: 0.0945 ========\nEpoch 1 Accuracy:  0.6629\nEpoch 1 Precision: 0.6742\nEpoch 1 Recall:    0.6629\nEpoch 1 F1-score:  0.6654\n\n======== Epoch 2 Training Loss: 0.0128 ========\nEpoch 2 Accuracy:  0.6600\nEpoch 2 Precision: 0.6620\nEpoch 2 Recall:    0.6600\nEpoch 2 F1-score:  0.6591\n\n======== Epoch 3 Training Loss: 1.5136 ========\nEpoch 3 Accuracy:  0.6609\nEpoch 3 Precision: 0.6646\nEpoch 3 Recall:    0.6609\nEpoch 3 F1-score:  0.6619\n\n======== Epoch 4 Training Loss: 0.0027 ========\nEpoch 4 Accuracy:  0.6593\nEpoch 4 Precision: 0.6611\nEpoch 4 Recall:    0.6593\nEpoch 4 F1-score:  0.6586\n\n======== Epoch 5 Training Loss: 0.0006 ========\nEpoch 5 Accuracy:  0.6663\nEpoch 5 Precision: 0.6645\nEpoch 5 Recall:    0.6663\nEpoch 5 F1-score:  0.6630\n\n======== Epoch 6 Training Loss: 0.0005 ========\nEpoch 6 Accuracy:  0.6730\nEpoch 6 Precision: 0.6720\nEpoch 6 Recall:    0.6730\nEpoch 6 F1-score:  0.6709\n\n======== Epoch 7 Training Loss: 0.0026 ========\nEpoch 7 Accuracy:  0.6667\nEpoch 7 Precision: 0.6759\nEpoch 7 Recall:    0.6667\nEpoch 7 F1-score:  0.6679\n\n======== Epoch 8 Training Loss: 0.0030 ========\nEpoch 8 Accuracy:  0.6643\nEpoch 8 Precision: 0.6693\nEpoch 8 Recall:    0.6643\nEpoch 8 F1-score:  0.6641\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n\nfor epoch in range(10):\n    model.train()\n    \n    for batch in train_loader:\n        optimizer.zero_grad()\n        input_ids = batch[\"input_ids\"].cuda()\n        attention_mask = batch[\"attention_mask\"].cuda()\n        labels = batch[\"labels\"].cuda()\n\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels\n        )\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n    print(f\"\\n======== Epoch {epoch+1} Training Loss: {loss.item():.4f} ========\")\n\n    # -------------------------------\n    # ðŸ”¥ Evaluate after each epoch\n    # -------------------------------\n    model.eval()\n    epoch_preds = []\n    epoch_true = []\n    val_losses = []\n\n    with torch.no_grad():\n        for batch in test_loader:\n            input_ids = batch[\"input_ids\"].cuda()\n            attention_mask = batch[\"attention_mask\"].cuda()\n            labels = batch[\"labels\"].cuda()\n\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n\n            # collect validation loss\n            val_losses.append(outputs.loss.item())\n\n            pred = torch.argmax(outputs.logits, dim=1)\n            epoch_preds.extend(pred.cpu().numpy())\n            epoch_true.extend(labels.cpu().numpy())\n\n    # Metrics\n    val_loss = sum(val_losses) / len(val_losses)\n    acc = accuracy_score(epoch_true, epoch_preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        epoch_true, epoch_preds, average='weighted', zero_division=0\n    )\n\n    print(f\"Epoch {epoch+1} Validation Loss: {val_loss:.4f}\")\n    print(f\"Epoch {epoch+1} Accuracy:        {acc:.4f}\")\n    print(f\"Epoch {epoch+1} Precision:       {precision:.4f}\")\n    print(f\"Epoch {epoch+1} Recall:          {recall:.4f}\")\n    print(f\"Epoch {epoch+1} F1-score:        {f1:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T20:39:13.829377Z","iopub.execute_input":"2025-11-23T20:39:13.829657Z","iopub.status.idle":"2025-11-23T21:17:08.638260Z","shell.execute_reply.started":"2025-11-23T20:39:13.829637Z","shell.execute_reply":"2025-11-23T21:17:08.637583Z"}},"outputs":[{"name":"stdout","text":"\n======== Epoch 1 Training Loss: 0.0010 ========\nEpoch 1 Validation Loss: 1.8463\nEpoch 1 Accuracy:        0.6597\nEpoch 1 Precision:       0.6585\nEpoch 1 Recall:          0.6597\nEpoch 1 F1-score:        0.6577\n\n======== Epoch 2 Training Loss: 0.0032 ========\nEpoch 2 Validation Loss: 1.8882\nEpoch 2 Accuracy:        0.6709\nEpoch 2 Precision:       0.6704\nEpoch 2 Recall:          0.6709\nEpoch 2 F1-score:        0.6680\n\n======== Epoch 3 Training Loss: 0.0040 ========\nEpoch 3 Validation Loss: 1.9318\nEpoch 3 Accuracy:        0.6653\nEpoch 3 Precision:       0.6825\nEpoch 3 Recall:          0.6653\nEpoch 3 F1-score:        0.6689\n\n======== Epoch 4 Training Loss: 0.1792 ========\nEpoch 4 Validation Loss: 1.8888\nEpoch 4 Accuracy:        0.6784\nEpoch 4 Precision:       0.6823\nEpoch 4 Recall:          0.6784\nEpoch 4 F1-score:        0.6793\n\n======== Epoch 5 Training Loss: 0.0054 ========\nEpoch 5 Validation Loss: 1.8773\nEpoch 5 Accuracy:        0.6622\nEpoch 5 Precision:       0.6647\nEpoch 5 Recall:          0.6622\nEpoch 5 F1-score:        0.6618\n\n======== Epoch 6 Training Loss: 0.0067 ========\nEpoch 6 Validation Loss: 2.0141\nEpoch 6 Accuracy:        0.6643\nEpoch 6 Precision:       0.6717\nEpoch 6 Recall:          0.6643\nEpoch 6 F1-score:        0.6639\n\n======== Epoch 7 Training Loss: 0.0017 ========\nEpoch 7 Validation Loss: 1.8688\nEpoch 7 Accuracy:        0.6803\nEpoch 7 Precision:       0.6806\nEpoch 7 Recall:          0.6803\nEpoch 7 F1-score:        0.6795\n\n======== Epoch 8 Training Loss: 0.0074 ========\nEpoch 8 Validation Loss: 1.9482\nEpoch 8 Accuracy:        0.6704\nEpoch 8 Precision:       0.6660\nEpoch 8 Recall:          0.6704\nEpoch 8 F1-score:        0.6655\n\n======== Epoch 9 Training Loss: 0.0024 ========\nEpoch 9 Validation Loss: 1.9656\nEpoch 9 Accuracy:        0.6735\nEpoch 9 Precision:       0.6761\nEpoch 9 Recall:          0.6735\nEpoch 9 F1-score:        0.6722\n\n======== Epoch 10 Training Loss: 0.0012 ========\nEpoch 10 Validation Loss: 1.9121\nEpoch 10 Accuracy:        0.6779\nEpoch 10 Precision:       0.6788\nEpoch 10 Recall:          0.6779\nEpoch 10 F1-score:        0.6772\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"model.save_pretrained(\"emotion_model\")\ntokenizer.save_pretrained(\"emotion_model\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T21:18:53.994014Z","iopub.execute_input":"2025-11-23T21:18:53.994284Z","iopub.status.idle":"2025-11-23T21:18:55.387665Z","shell.execute_reply.started":"2025-11-23T21:18:53.994265Z","shell.execute_reply":"2025-11-23T21:18:55.387045Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"('emotion_model/tokenizer_config.json',\n 'emotion_model/special_tokens_map.json',\n 'emotion_model/vocab.txt',\n 'emotion_model/added_tokens.json',\n 'emotion_model/tokenizer.json')"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"import pickle\n\nwith open(\"label_encoder.pkl\", \"wb\") as f:\n    pickle.dump(le, f)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T21:21:50.742979Z","iopub.execute_input":"2025-11-23T21:21:50.743238Z","iopub.status.idle":"2025-11-23T21:21:50.747498Z","shell.execute_reply.started":"2025-11-23T21:21:50.743221Z","shell.execute_reply":"2025-11-23T21:21:50.746936Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T21:21:57.364522Z","iopub.execute_input":"2025-11-23T21:21:57.364787Z","iopub.status.idle":"2025-11-23T21:21:57.533131Z","shell.execute_reply.started":"2025-11-23T21:21:57.364767Z","shell.execute_reply":"2025-11-23T21:21:57.532126Z"}},"outputs":[{"name":"stdout","text":"\u001b[0m\u001b[01;34memotion_model\u001b[0m/  label_encoder.pkl\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification\nimport torch\nimport pickle\n\n# Load model + tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"emotion_model\")\nmodel = AutoModelForSequenceClassification.from_pretrained(\"emotion_model\")\nmodel.eval()\n\n# Load label encoder\nwith open(\"label_encoder.pkl\", \"rb\") as f:\n    le = pickle.load(f)\n\n# Prediction function\ndef predict_emotion(text):\n    inputs = tokenizer(\n        text,\n        return_tensors=\"pt\",\n        truncation=True,\n        padding=True,\n        max_length=80\n    )\n    \n    with torch.no_grad():\n        outputs = model(**inputs)\n        pred = torch.argmax(outputs.logits, dim=1).item()\n    \n    emotion = le.inverse_transform([pred])[0]\n    return emotion\n\n\n# Test\nprint(predict_emotion(\"amar mon kharap lagse\"))\nprint(predict_emotion(\"amar friend er onek jor hoyeche\"))\nprint(predict_emotion(\"ajke amar onek voy lagse\"))\nprint(predict_emotion(\"Rat 3 tai ami aka gore\"))\nprint(predict_emotion(\"amar khob rag hoche\"))\nprint(predict_emotion(\"Aj ami onek khusi kinto tension e achi\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-23T21:26:34.380703Z","iopub.execute_input":"2025-11-23T21:26:34.381339Z","iopub.status.idle":"2025-11-23T21:26:34.777993Z","shell.execute_reply.started":"2025-11-23T21:26:34.381309Z","shell.execute_reply":"2025-11-23T21:26:34.777242Z"}},"outputs":[{"name":"stdout","text":"Fear\nSadness\nFear\nJoy\nFear\nFear\n","output_type":"stream"}],"execution_count":27}]}